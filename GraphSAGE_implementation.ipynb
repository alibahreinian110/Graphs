{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3q8r_V2rC2At"
      },
      "outputs": [],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.nn import SAGEConv"
      ],
      "metadata": {
        "id": "_V_Cn2uVDBgv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSAGE(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "    super(GraphSAGE, self).__init__()\n",
        "    self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
        "    self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    x = self.conv1(x, edge_index)\n",
        "    x = torch.relu(x)\n",
        "    x = self.conv2(x, edge_index)\n",
        "    return x"
      ],
      "metadata": {
        "id": "5UB-z1UYDKMy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import Planetoid\n",
        "dataset = Planetoid(root='/tmp/Cora', name = 'Cora')\n",
        "data = dataset[0]"
      ],
      "metadata": {
        "id": "7xr9Oe1tEoxR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset.num_node_features\n",
        "y = dataset.num_classes\n",
        "\n",
        "model = GraphSAGE(x, 16, y)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "AI2Wwy4sFEpE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcHidgTIGUja",
        "outputId": "6555fc78-2666-442f-c54c-c65e285efc37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GraphSAGE(\n",
              "  (conv1): SAGEConv(1433, 16, aggr=mean)\n",
              "  (conv2): SAGEConv(16, 7, aggr=mean)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(200):\n",
        "  optimizer.zero_grad()\n",
        "  out = model(data.x, data.edge_index)\n",
        "  loss = torch.nn.functional.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "id": "ariLTJ-DFycA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "_, pred = model(data.x, data.edge_index).max(dim = 1)\n",
        "correct = int(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
        "acc = correct / int(data.test_mask.sum())\n",
        "print(f'Accuracy: {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYmZGlegcW-_",
        "outputId": "f015efc2-2cb8-44bc-fa41-21970547e83d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Mini-Batches"
      ],
      "metadata": {
        "id": "jI2yvtm04VkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset, batch_size = 32, shuffle = True)"
      ],
      "metadata": {
        "id": "uhr8dJ22hZ77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455f04f0-da7d-4014-94e4-f5c2bac2c786"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(501):\n",
        "  for batch in loader:\n",
        "    optimizer.zero_grad()\n",
        "    x, edge_index = batch.x, batch.edge_index\n",
        "    out = model(x, edge_index)\n",
        "    loss = torch.nn.functional.cross_entropy(out, batch.y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "      print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jZBxDfT5PYd",
        "outputId": "3ad82add-734e-48f4-cd6a-15b7b42325aa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 0.0003\n",
            "Epoch: 100, Loss: 0.0002\n",
            "Epoch: 200, Loss: 0.0001\n",
            "Epoch: 300, Loss: 0.0001\n",
            "Epoch: 400, Loss: 0.0001\n",
            "Epoch: 500, Loss: 0.0001\n"
          ]
        }
      ]
    }
  ]
}